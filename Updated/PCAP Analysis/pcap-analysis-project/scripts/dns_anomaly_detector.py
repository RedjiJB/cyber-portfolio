#!/usr/bin/env python3
"""
DNS Anomaly Detector
Detects DNS tunneling, DGA domains, and other DNS anomalies in PCAP files
"""

import argparse
import sys
import re
import math
import json
from collections import defaultdict, Counter
from datetime import datetime
from scapy.all import *
from scapy.layers.dns import DNS, DNSQR, DNSRR
import numpy as np
from scipy import stats

class DNSAnomalyDetector:
    def __init__(self, pcap_file):
        self.pcap_file = pcap_file
        self.dns_queries = []
        self.statistics = {
            'total_packets': 0,
            'dns_packets': 0,
            'unique_domains': 0,
            'suspicious_domains': 0,
            'possible_dga': 0,
            'possible_tunneling': 0,
            'high_entropy_domains': 0,
            'excessive_subdomains': 0,
            'suspicious_record_types': 0
        }
        self.anomalies = defaultdict(list)
        self.domain_stats = defaultdict(lambda: {'count': 0, 'subdomains': set(), 'record_types': set()})
        
        # DGA detection thresholds
        self.entropy_threshold = 3.5
        self.consonant_ratio_threshold = 0.65
        self.digit_ratio_threshold = 0.3
        self.length_threshold = 15
        
        # DNS tunneling thresholds
        self.subdomain_length_threshold = 50
        self.query_rate_threshold = 10  # queries per second
        self.txt_record_size_threshold = 255
        
        # Common TLDs for legitimate domains
        self.common_tlds = {'.com', '.org', '.net', '.edu', '.gov', '.co.uk', '.de', '.fr', '.jp', '.cn'}
        
    def calculate_entropy(self, string):
        """Calculate Shannon entropy of a string"""
        if not string:
            return 0
        
        prob = [float(string.count(c)) / len(string) for c in dict.fromkeys(string)]
        entropy = -sum([p * math.log(p) / math.log(2.0) for p in prob if p > 0])
        return entropy
    
    def calculate_consonant_ratio(self, string):
        """Calculate ratio of consonants to total characters"""
        vowels = 'aeiouAEIOU'
        consonants = sum(1 for c in string if c.isalpha() and c not in vowels)
        total_letters = sum(1 for c in string if c.isalpha())
        
        if total_letters == 0:
            return 0
        
        return consonants / total_letters
    
    def calculate_digit_ratio(self, string):
        """Calculate ratio of digits to total characters"""
        digits = sum(1 for c in string if c.isdigit())
        return digits / len(string) if string else 0
    
    def is_dga_domain(self, domain):
        """Check if domain appears to be generated by DGA"""
        # Remove TLD for analysis
        parts = domain.split('.')
        if len(parts) < 2:
            return False, {}
        
        domain_name = parts[0]  # Analyze the main domain part
        
        # Calculate various metrics
        entropy = self.calculate_entropy(domain_name)
        consonant_ratio = self.calculate_consonant_ratio(domain_name)
        digit_ratio = self.calculate_digit_ratio(domain_name)
        length = len(domain_name)
        
        # Check for suspicious patterns
        suspicious_patterns = []
        
        if entropy > self.entropy_threshold:
            suspicious_patterns.append(f"High entropy: {entropy:.2f}")
        
        if consonant_ratio > self.consonant_ratio_threshold:
            suspicious_patterns.append(f"High consonant ratio: {consonant_ratio:.2f}")
        
        if digit_ratio > self.digit_ratio_threshold:
            suspicious_patterns.append(f"High digit ratio: {digit_ratio:.2f}")
        
        if length > self.length_threshold:
            suspicious_patterns.append(f"Long domain name: {length} chars")
        
        # Check for random-looking patterns
        if re.match(r'^[a-z0-9]{10,}$', domain_name.lower()):
            suspicious_patterns.append("Random alphanumeric pattern")
        
        # Check for uncommon TLD
        tld = '.' + '.'.join(parts[1:])
        if tld not in self.common_tlds and len(tld) > 4:
            suspicious_patterns.append(f"Uncommon TLD: {tld}")
        
        is_dga = len(suspicious_patterns) >= 2
        
        return is_dga, {
            'entropy': entropy,
            'consonant_ratio': consonant_ratio,
            'digit_ratio': digit_ratio,
            'length': length,
            'patterns': suspicious_patterns
        }
    
    def detect_dns_tunneling(self, domain, record_type, answer_data=None):
        """Detect potential DNS tunneling"""
        indicators = []
        
        # Check subdomain length
        parts = domain.split('.')
        if len(parts) > 2:
            subdomain = '.'.join(parts[:-2])
            if len(subdomain) > self.subdomain_length_threshold:
                indicators.append(f"Long subdomain: {len(subdomain)} chars")
        
        # Check for base64-like patterns in subdomain
        if len(parts) > 2:
            subdomain = parts[0]
            if re.match(r'^[A-Za-z0-9+/]+=*$', subdomain) and len(subdomain) > 20:
                indicators.append("Base64-like subdomain pattern")
        
        # Check for hex encoding patterns
        if len(parts) > 2:
            subdomain = parts[0]
            if re.match(r'^[0-9a-fA-F]+$', subdomain) and len(subdomain) > 16:
                indicators.append("Hex-encoded subdomain pattern")
        
        # Check TXT record abuse
        if record_type == 'TXT' and answer_data:
            if len(answer_data) > self.txt_record_size_threshold:
                indicators.append(f"Large TXT record: {len(answer_data)} bytes")
        
        # Check for unusual record types used for tunneling
        suspicious_types = ['NULL', 'PRIVATE', 'TXT']
        if record_type in suspicious_types:
            indicators.append(f"Suspicious record type: {record_type}")
        
        return len(indicators) > 0, indicators
    
    def analyze_query_patterns(self):
        """Analyze query patterns for anomalies"""
        # Group queries by source IP
        queries_by_ip = defaultdict(list)
        for query in self.dns_queries:
            queries_by_ip[query['src_ip']].append(query)
        
        # Analyze each IP's query patterns
        for ip, queries in queries_by_ip.items():
            # Sort by timestamp
            queries.sort(key=lambda x: x['timestamp'])
            
            # Check query rate
            if len(queries) > 10:
                time_range = queries[-1]['timestamp'] - queries[0]['timestamp']
                if time_range > 0:
                    query_rate = len(queries) / time_range
                    if query_rate > self.query_rate_threshold:
                        self.anomalies['high_query_rate'].append({
                            'ip': ip,
                            'rate': query_rate,
                            'query_count': len(queries),
                            'time_range': time_range
                        })
            
            # Check for sequential subdomain patterns (common in tunneling)
            domains = [q['domain'] for q in queries]
            sequential_pattern = self.detect_sequential_pattern(domains)
            if sequential_pattern:
                self.anomalies['sequential_pattern'].append({
                    'ip': ip,
                    'pattern': sequential_pattern,
                    'sample_domains': domains[:5]
                })
    
    def detect_sequential_pattern(self, domains):
        """Detect sequential patterns in domain names"""
        if len(domains) < 3:
            return None
        
        # Check for incrementing numbers or letters in subdomains
        subdomain_parts = []
        for domain in domains[:10]:  # Check first 10 domains
            parts = domain.split('.')
            if len(parts) > 2:
                subdomain_parts.append(parts[0])
        
        if len(subdomain_parts) >= 3:
            # Check for numeric sequences
            numbers = []
            for part in subdomain_parts:
                match = re.search(r'\d+', part)
                if match:
                    numbers.append(int(match.group()))
            
            if len(numbers) >= 3:
                # Check if numbers are sequential
                if all(numbers[i+1] - numbers[i] == 1 for i in range(len(numbers)-1)):
                    return "Incrementing numeric sequence"
        
        return None
    
    def process_dns_packet(self, packet):
        """Process DNS packets"""
        if packet.haslayer(DNS):
            self.statistics['dns_packets'] += 1
            
            # Extract basic information
            src_ip = packet[IP].src if packet.haslayer(IP) else 'Unknown'
            dst_ip = packet[IP].dst if packet.haslayer(IP) else 'Unknown'
            
            # Process DNS queries
            if packet[DNS].qr == 0:  # DNS query
                for i in range(packet[DNS].qdcount):
                    if packet.haslayer(DNSQR):
                        qname = packet[DNSQR].qname.decode('utf-8', errors='ignore').rstrip('.')
                        qtype = packet[DNSQR].qtype
                        
                        # Record query
                        query_info = {
                            'domain': qname,
                            'type': qtype,
                            'src_ip': src_ip,
                            'dst_ip': dst_ip,
                            'timestamp': float(packet.time)
                        }
                        self.dns_queries.append(query_info)
                        
                        # Update domain statistics
                        self.domain_stats[qname]['count'] += 1
                        self.domain_stats[qname]['record_types'].add(qtype)
                        
                        # Check for DGA
                        is_dga, dga_info = self.is_dga_domain(qname)
                        if is_dga:
                            self.statistics['possible_dga'] += 1
                            self.anomalies['dga_domains'].append({
                                'domain': qname,
                                'src_ip': src_ip,
                                'timestamp': datetime.fromtimestamp(float(packet.time)).isoformat(),
                                'indicators': dga_info
                            })
                        
                        # Check for DNS tunneling
                        is_tunnel, tunnel_indicators = self.detect_dns_tunneling(qname, qtype)
                        if is_tunnel:
                            self.statistics['possible_tunneling'] += 1
                            self.anomalies['dns_tunneling'].append({
                                'domain': qname,
                                'src_ip': src_ip,
                                'record_type': qtype,
                                'timestamp': datetime.fromtimestamp(float(packet.time)).isoformat(),
                                'indicators': tunnel_indicators
                            })
                        
                        # Check for high entropy domains
                        entropy = self.calculate_entropy(qname.split('.')[0])
                        if entropy > self.entropy_threshold:
                            self.statistics['high_entropy_domains'] += 1
                        
                        # Track subdomains
                        parts = qname.split('.')
                        if len(parts) > 2:
                            parent_domain = '.'.join(parts[-2:])
                            subdomain = '.'.join(parts[:-2])
                            self.domain_stats[parent_domain]['subdomains'].add(subdomain)
            
            # Process DNS responses
            elif packet[DNS].qr == 1:  # DNS response
                if packet[DNS].ancount > 0:
                    for i in range(packet[DNS].ancount):
                        if packet.haslayer(DNSRR):
                            # Check response data for tunneling indicators
                            if hasattr(packet[DNSRR], 'rdata'):
                                rdata = str(packet[DNSRR].rdata)
                                if packet[DNSRR].type == 16:  # TXT record
                                    is_tunnel, indicators = self.detect_dns_tunneling(
                                        packet[DNSRR].rrname.decode('utf-8', errors='ignore'),
                                        'TXT',
                                        rdata
                                    )
                                    if is_tunnel:
                                        self.statistics['possible_tunneling'] += 1
    
    def process_packet(self, packet):
        """Process a single packet"""
        self.statistics['total_packets'] += 1
        
        try:
            self.process_dns_packet(packet)
        except Exception as e:
            pass  # Continue processing other packets
    
    def analyze(self):
        """Analyze the PCAP file"""
        print(f"[*] Loading PCAP file: {self.pcap_file}")
        
        try:
            # Process packets
            sniff(offline=self.pcap_file, prn=self.process_packet, store=0)
            
            # Analyze patterns after processing all packets
            self.analyze_query_patterns()
            
            # Calculate final statistics
            self.statistics['unique_domains'] = len(self.domain_stats)
            
            # Check for domains with excessive subdomains
            for domain, stats in self.domain_stats.items():
                if len(stats['subdomains']) > 50:
                    self.statistics['excessive_subdomains'] += 1
                    self.anomalies['excessive_subdomains'].append({
                        'domain': domain,
                        'subdomain_count': len(stats['subdomains']),
                        'sample_subdomains': list(stats['subdomains'])[:10]
                    })
            
            return True
        except Exception as e:
            print(f"[!] Error analyzing PCAP: {str(e)}")
            return False
    
    def print_results(self):
        """Print analysis results"""
        print("\n" + "="*60)
        print("DNS ANOMALY DETECTION RESULTS")
        print("="*60)
        
        print(f"\nStatistics:")
        print(f"  Total packets analyzed: {self.statistics['total_packets']}")
        print(f"  DNS packets: {self.statistics['dns_packets']}")
        print(f"  Unique domains: {self.statistics['unique_domains']}")
        print(f"  Possible DGA domains: {self.statistics['possible_dga']}")
        print(f"  Possible DNS tunneling: {self.statistics['possible_tunneling']}")
        print(f"  High entropy domains: {self.statistics['high_entropy_domains']}")
        print(f"  Domains with excessive subdomains: {self.statistics['excessive_subdomains']}")
        
        # Print DGA domains
        if self.anomalies['dga_domains']:
            print(f"\nPossible DGA Domains ({len(self.anomalies['dga_domains'])}):")
            print("-"*60)
            for i, dga in enumerate(self.anomalies['dga_domains'][:10]):
                print(f"\n[{i+1}] Domain: {dga['domain']}")
                print(f"    Source IP: {dga['src_ip']}")
                print(f"    Timestamp: {dga['timestamp']}")
                print(f"    Entropy: {dga['indicators']['entropy']:.2f}")
                print(f"    Indicators: {', '.join(dga['indicators']['patterns'])}")
            
            if len(self.anomalies['dga_domains']) > 10:
                print(f"\n... and {len(self.anomalies['dga_domains']) - 10} more DGA domains")
        
        # Print DNS tunneling suspects
        if self.anomalies['dns_tunneling']:
            print(f"\nPossible DNS Tunneling ({len(self.anomalies['dns_tunneling'])}):")
            print("-"*60)
            for i, tunnel in enumerate(self.anomalies['dns_tunneling'][:10]):
                print(f"\n[{i+1}] Domain: {tunnel['domain']}")
                print(f"    Source IP: {tunnel['src_ip']}")
                print(f"    Record Type: {tunnel['record_type']}")
                print(f"    Timestamp: {tunnel['timestamp']}")
                print(f"    Indicators: {', '.join(tunnel['indicators'])}")
            
            if len(self.anomalies['dns_tunneling']) > 10:
                print(f"\n... and {len(self.anomalies['dns_tunneling']) - 10} more tunneling suspects")
        
        # Print high query rate IPs
        if self.anomalies['high_query_rate']:
            print(f"\nHigh Query Rate IPs:")
            print("-"*60)
            for anomaly in self.anomalies['high_query_rate']:
                print(f"\nIP: {anomaly['ip']}")
                print(f"  Query rate: {anomaly['rate']:.2f} queries/second")
                print(f"  Total queries: {anomaly['query_count']}")
        
        # Print top queried domains
        print(f"\nTop 10 Queried Domains:")
        print("-"*60)
        sorted_domains = sorted(self.domain_stats.items(), 
                              key=lambda x: x[1]['count'], 
                              reverse=True)[:10]
        for domain, stats in sorted_domains:
            print(f"  {domain}: {stats['count']} queries")
    
    def save_results(self, output_file):
        """Save results to JSON file"""
        results = {
            'analysis_timestamp': datetime.now().isoformat(),
            'pcap_file': self.pcap_file,
            'statistics': self.statistics,
            'anomalies': dict(self.anomalies),
            'top_domains': dict(sorted(self.domain_stats.items(), 
                                     key=lambda x: x[1]['count'], 
                                     reverse=True)[:50])
        }
        
        # Convert sets to lists for JSON serialization
        for domain in results['top_domains']:
            results['top_domains'][domain]['subdomains'] = list(results['top_domains'][domain]['subdomains'])
            results['top_domains'][domain]['record_types'] = list(results['top_domains'][domain]['record_types'])
        
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\n[+] Results saved to: {output_file}")

def main():
    parser = argparse.ArgumentParser(
        description='Detect DNS anomalies, tunneling, and DGA domains in PCAP files',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  %(prog)s capture.pcap
  %(prog)s capture.pcap -o results.json
  %(prog)s capture.pcap --entropy-threshold 4.0
  %(prog)s capture.pcap --verbose
        '''
    )
    
    parser.add_argument('pcap_file', help='Path to PCAP file')
    parser.add_argument('-o', '--output', help='Output JSON file for results')
    parser.add_argument('--entropy-threshold', type=float, default=3.5,
                       help='Entropy threshold for DGA detection (default: 3.5)')
    parser.add_argument('--subdomain-length', type=int, default=50,
                       help='Subdomain length threshold for tunneling detection (default: 50)')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    
    args = parser.parse_args()
    
    # Check if file exists
    if not os.path.exists(args.pcap_file):
        print(f"[!] Error: PCAP file not found: {args.pcap_file}")
        sys.exit(1)
    
    # Create detector
    detector = DNSAnomalyDetector(args.pcap_file)
    
    # Apply custom thresholds if provided
    if args.entropy_threshold:
        detector.entropy_threshold = args.entropy_threshold
    if args.subdomain_length:
        detector.subdomain_length_threshold = args.subdomain_length
    
    # Analyze PCAP
    if detector.analyze():
        # Print results
        detector.print_results()
        
        # Save results if output file specified
        if args.output:
            detector.save_results(args.output)
    else:
        sys.exit(1)

if __name__ == '__main__':
    main()